{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crack Detection using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will take part of a [Kaggle competition](https://www.kaggle.com/t/28f427df84ea4d06a395beb6a0436cd3). For those of you who never heard about it before, Kaggle is an online data science community with lots of interesting data sets, codes, open competitions, etc. In Kaggle, I set up a competition for this assignment---you can download necessary data for this assignment from it, view samples, and submit your results to get them graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, open [this link](https://www.kaggle.com/t/28f427df84ea4d06a395beb6a0436cd3) and browse through the competition page. The webpage will walk you through the details of data and how to make a submission.\n",
    "\n",
    "To download the dataset, there are basically two ways. An easy (but perhaps more time-consuming) way is to just click `Data` tab in the competition page, and hit `Download All` button. It will then download the entire dataset in a zip file, which you can extract to a desired location.\n",
    "\n",
    "Alaternatively, you can also use Kaggle CLI (Command Line Interface), which can be installed via the following command in terminal:\n",
    "```bash\n",
    "pip install kaggle\n",
    "```\n",
    "After installing it, go to the `Account` tab of your user profile on Kaggle and select `Create New Token`. This will trigger the download of `kaggle.json`, a file containing your API credentials. The Kaggle CLI tool will look for this token at `~/.kaggle/kaggle.json` on Linux, OSX, and other UNIX-based operating systems, and at `C:\\Users\\<username>\\.kaggle\\kaggle.json` on Windows. If you are using Google Colab, see '[How to use the Kaggle API from Colab](https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb).'\n",
    "\n",
    "Once the configuration is complete, running the following command in terminal will let you download the dataset:\n",
    "```bash\n",
    "kaggle competitions download -c <competition-name> -p <download-folder>\n",
    "```\n",
    "\n",
    "In our case, executing the following sell will let you download the competition dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c padl-assignment-1-concrete-crack-detection -p ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can unzip the file using Python `zipfile` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/padl-assignment-1-concrete-crack-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('data/padl-assignment-1-concrete-crack-detection.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "if platform.system() == \"Windows\":\n",
    "    !dir \"{data_dir}\"\n",
    "else:\n",
    "    !ls \"{data_dir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Okay, now that we have downloaded all the competition data from Kaggle, let's start loading them. As our usual step, we are going to import PyTorch and find an available device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else: \n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "image_width = 64     # TODO: Change the image size to optimize the performance\n",
    "image_height = 64    # TODO: Change the image size to optimize the performance\n",
    "batch_size = 32      # TODO: Change the batch size to optimize the performance\n",
    "transform = transforms.Compose([   # TODO: Explore other image transformations to optimize the performance\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((image_height, image_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(torch.flatten)  # TODO: We are flattening image to a 1D vector to make it compatible with MLP. For CNN, remove this line.\n",
    "])\n",
    "dataset = datasets.ImageFolder(data_dir + '/train', transform=transform)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8*dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images, labels = next(iter(train_loader))\n",
    "plt.figure()\n",
    "for i, (image, label) in enumerate(zip(images, labels)):\n",
    "    plt.subplot(4,8,i+1)\n",
    "    plt.imshow(image.reshape(image_height,image_width),cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(dataset.classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design\n",
    "\n",
    "Below is a simple baseline model for testing. Design your own model here to make it perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # TODO: Try different architecture design (e.g., your own CNN, transfer a pre-trained CNN, etc.)\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Try different architecture design\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleClassifier(num_inputs=image_height*image_width, num_hidden=4096, num_outputs=1)\n",
    "\n",
    "# Printing a module shows all its submodules\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Finally, it's time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try different optimizers and parameter combinations\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)    # Load the model to the device\n",
    "\n",
    "loss_module = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100     # TODO: Increase the number of epochs (e.g., 1000) to see if it converges better\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()       # Set model to train mode\n",
    "    running_loss = 0\n",
    "    for i, (data_inputs, data_labels) in enumerate(train_loader):\n",
    "\n",
    "        ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "        data_inputs = data_inputs.to(device)\n",
    "        data_labels = data_labels.to(device)\n",
    "\n",
    "        ## Step 2: Run the model on the input data\n",
    "        preds = model(data_inputs)\n",
    "        preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "\n",
    "        ## Step 3: Calculate the loss\n",
    "        loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "        ## Step 4: Perform backpropagation\n",
    "        # Before calculating the gradients, we need to ensure that they are all zero.\n",
    "        # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "        optimizer.zero_grad()\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        ## Step 5: Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        ## Step 6: Print the progress before moving to the next iteration\n",
    "        running_loss += loss.detach().cpu().numpy()\n",
    "        print(f\"Epoch {epoch} loss: {running_loss/(i+1)}\", end='\\r')\n",
    "    avg_train_loss = running_loss / i\n",
    "\n",
    "    # Repeat the same, but this time on the validation data to evaluate the progress\n",
    "    model.eval()       # Set model to evaluation mode\n",
    "    running_val_loss = 0\n",
    "    for i, (data_inputs, data_labels) in enumerate(val_loader):\n",
    "        \n",
    "        data_inputs = data_inputs.to(device)\n",
    "        data_labels = data_labels.to(device)\n",
    "\n",
    "        preds = model(data_inputs)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "\n",
    "        loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "        # For validation data, we skip backpropagation (we are not training!)\n",
    "\n",
    "        running_val_loss += loss.detach().cpu().numpy()\n",
    "        print(f\"Epoch {epoch} - loss: {avg_train_loss}, val: {running_val_loss/(i+1)}\", end='\\r')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() # Set model to eval mode\n",
    "    true_preds, num_preds = 0., 0.\n",
    "\n",
    "    with torch.no_grad(): # Deactivate gradients for the following code\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "\n",
    "            # Determine prediction of model on dev set\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
    "\n",
    "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "\n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model trained, let's evaluate it on the test data. To do so, we create a separate test data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Custom dataset class to keep track of the filename\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([   # Be careful: No other data augmentation should be included in test transform\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((image_height, image_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(torch.flatten)  # TODO: We are flattening image to a 1D vector to make it compatible with MLP. For CNN, remove this line.\n",
    "])\n",
    "test_dataset = TestDataset(data_dir + '/test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # Set model to eval mode\n",
    "\n",
    "predictions = {}\n",
    "with torch.no_grad(): # Deactivate gradients for the following code\n",
    "    for data_inputs, filenames in test_loader:\n",
    "\n",
    "        # Infer model on a test batch\n",
    "        data_inputs = data_inputs.to(device)\n",
    "        preds = model(data_inputs)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "        preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "        pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
    "\n",
    "        for filename, pred in zip(filenames, pred_labels):\n",
    "            predictions[filename] = int(pred.detach().cpu().numpy())\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Write the result to a CSV file\n",
    "csv_file = 'submission.csv'\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header\n",
    "    writer.writerow(['FILENAME', 'TARGET'])\n",
    "    # Write content\n",
    "    for filename, label in predictions.items():\n",
    "        writer.writerow([filename, label])\n",
    "\n",
    "print(f\"Prediction results have been successfully written to {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can submit it through either the [competition page](https://www.kaggle.com/competitions/padl-assignment-1-concrete-crack-detection) or the following command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c padl-assignment-1-concrete-crack-detection -f submission.csv -m [PROVIDE-A-SHORT-DESCRIPTION]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
