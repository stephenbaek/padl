{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks - Harmonic Oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import IPython.display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils import save_progress, make_gif, reset_parameters\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap on (Damped) Harmonic Oscillators\n",
    "\n",
    "In classical mechanics, a harmonic oscillator is a system in which a mass experiences a restoring force proportional to its displacement from equilibrium. If we let $x$ be the displacement of the mass $m$ from the equilibrium $x=0$, by the Hooke's law, the restoring force $F_r$ has the following form:\n",
    "\n",
    "$$F_r=-kx.$$\n",
    "\n",
    "Also, from the Newton's second law of motion $F=m\\frac{\\partial^2 x}{\\partial t^2}$, where the second order derivative with respect to time $t$, we have the following relationship:\n",
    "\n",
    "$$m\\frac{\\partial^2 x}{\\partial t^2} + kx = 0.$$\n",
    "\n",
    "In an ideal harmonic oscillator as in the above, the mass oscillates indefinitely with constant amplitude and frequency. However, real-world oscillators are often damped and experience a resistive or damping force that opposes its motion. This means that they gradually lose energy due to frictional or resistive forces, causing the oscillations to decrease in amplitude over time. Such a damping force, say $F_d$ can be modeled as being proportional to the velocity $\\frac{\\partial x}{\\partial t}$ of the mass, or $F_d=-c\\frac{\\partial x}{\\partial t}$, where $c$ is called the damping coefficient.\n",
    "\n",
    "The Newton's second law for damped harmonic oscillators then becomes:\n",
    "\n",
    "$$F_\\text{total} = F_r + F_d = -kx-c\\frac{\\partial x}{\\partial t} = m\\frac{\\partial^2 x}{\\partial t^2},$$\n",
    "\n",
    "which can be rewritten into a more intuitive form:\n",
    "\n",
    "$$\\frac{\\partial^2 x}{\\partial t^2} + 2\\zeta\\omega_0\\frac{\\partial x}{\\partial t} + \\omega_0^2 x = 0,$$\n",
    "\n",
    "where $\\omega_0:=\\sqrt{\\frac{k}{m}}$ is the angular frequency of the oscillator and $\\zeta:=\\frac{c}{2\\sqrt{mk}}$ is called the damping ratio.\n",
    "\n",
    "The value of the damping ratio can vary and critically determine the behavior of the system, affecting whether the system returns to equilibrium without oscillating (overdamping; $\\zeta>1$), oscillates with a gradually reducing amplitude (underdamping; $\\zeta<1$), or quickly comes to rest without oscillating (critical damping; $\\zeta=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the Ground Truth (Analytic Solution)\n",
    "\n",
    "In the underdamped or critically damped cases where $\\zeta \\leq 1$, the analytical solution for the state space representation of a damped harmonic oscillator can be expressed as damped sinusoidal oscillations:\n",
    "\n",
    "$$\\mathbf{x}(t) = ae^{-\\zeta\\omega_0 t}\\sin(\\sqrt{1-\\zeta^2}\\omega_0t + \\varphi),$$\n",
    "\n",
    "where the amplitude $a$ and phase $\\varphi$ are coefficients determined from the initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineCoefficients(X0, zeta, omega0):\n",
    "    ''' Determine amplitude a and phase phi.\n",
    "\n",
    "    Inputs:\n",
    "        X0: torch.tensor of size (2,) containing initial position and velocity.\n",
    "        zeta: damping ratio.\n",
    "        omega0: angular frequency.\n",
    "\n",
    "    Returns:\n",
    "        Amplitude a and phase phi that match the initial condition X0.\n",
    "    '''\n",
    "    assert zeta <= 1, \"zeta must be under-/critically-damped (zeta <= 1)\"\n",
    "\n",
    "    if torch.abs((X0[1] + zeta*omega0*X0[0])) < 1e-7:\n",
    "        phi = 0.5*torch.pi\n",
    "    else:\n",
    "        num = torch.sqrt(torch.tensor(1-zeta**2, dtype=dtype))*omega0*X0[0]\n",
    "        den = X0[1] + zeta*omega0*X0[0]\n",
    "        phi = torch.arctan(num/den)\n",
    "    a = X0[0]/torch.sin(phi)\n",
    "\n",
    "    return a, phi\n",
    "\n",
    "\n",
    "# Initial condition\n",
    "X0 = torch.tensor([1, 0], dtype=dtype)   # initial condition\n",
    "omega0 = 2*torch.pi                      # angular frequency\n",
    "zeta = 0.15                               # damping ratio (<= 1)\n",
    "\n",
    "# Determine coefficients\n",
    "a, phi = determineCoefficients(X0, zeta, omega0)\n",
    "\n",
    "# Create ground truth data\n",
    "Nt = 1000    # number of time steps\n",
    "Tmax = 3\n",
    "t = torch.linspace(0, Tmax, Nt, dtype=dtype)\n",
    "\n",
    "# Compute the analytic solution (ground truth) for the state x(t)\n",
    "ezot = torch.exp(-zeta*omega0*t)\n",
    "sqrt_omega = torch.sqrt(torch.tensor(1-zeta**2, dtype=dtype))*omega0\n",
    "position = a*ezot*torch.sin(sqrt_omega*t + phi)\n",
    "GT = torch.unsqueeze(position,-1)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title('Position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data\n",
    "\n",
    "Now to train a model, let's sample training data. Here, we are going to assume a scenario where we only have a partial and discrete observation of the dynamics in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax_sample = 1.2       # maximum time for training sample\n",
    "sample_stride = 20       # stride between samples\n",
    "\n",
    "Nt_sample = int(Nt*Tmax_sample/Tmax)\n",
    "\n",
    "t_sample = torch.unsqueeze(t[0:Nt_sample:sample_stride], -1)\n",
    "GT_sample = GT[0:Nt_sample:sample_stride,:]\n",
    "\n",
    "training_data = torch.hstack((t_sample, GT_sample))  # t, x\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "plt.scatter(training_data[:,0], training_data[:,1], color='orange', label='Training Data')\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title('Position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design\n",
    "\n",
    "Now, let's design a model. Here, I'm providing a simple MLP implementation as a starter. But you are encouraged to experiment with different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(1, 32, dtype=dtype)  # input dim = 1 (t)\n",
    "        self.fc2 = nn.Linear(32, 32, dtype=dtype)  # hidden dims = 32, 32\n",
    "        self.fc3 = nn.Linear(32, 32, dtype=dtype)  #\n",
    "        self.out = nn.Linear(32, 1, dtype=dtype)  # output dim = 1 (x)\n",
    "\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.SiLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.SiLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.SiLU()(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model = Backbone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training WITHOUT Physics-Informed Loss Term\n",
    "\n",
    "Before we get started with PINN, we'll set up a simple training session without any physics informed loss terms to set a baseline. Of course, a physics-naive model would'nt generalize well beyond the observed range of dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress(t, GT, prediction, training_data, collocation_t=None):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(t, GT, color='black', label = \"Ground Truth\")\n",
    "    plt.plot(t, prediction, color='deepskyblue', label = \"PINN\")\n",
    "    plt.scatter(training_data[:,0], training_data[:,1], color='orange', label='Training Data')\n",
    "    if not collocation_t is None:\n",
    "        plt.scatter(collocation_t, torch.zeros_like(collocation_t), color='olive', label = \"Collocation Points\", s=20)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"x\")\n",
    "    plt.title(f'Position (Iteration={iter+1})')\n",
    "    plt.legend()\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "files = []\n",
    "\n",
    "save_dir = 'results/harmonic/nophysics'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "MAX_ITER = 30000\n",
    "input = training_data[:,:1].clone().detach()    # t\n",
    "output = training_data[:,1:].clone().detach()  # x\n",
    "for iter in range(MAX_ITER):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(input)\n",
    "    loss = torch.mean((output-prediction)**2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().numpy():.5e}\", end='\\r')\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (iter+1) % 100 == 0: \n",
    "        \n",
    "        prediction = model(torch.unsqueeze(t,axis=-1)).detach()\n",
    "        plot_progress(t, GT, prediction, training_data)\n",
    "        files.append(save_progress(save_dir, 'nophys', iter))\n",
    "    \n",
    "        if (iter+1) % 10000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate the training progress\n",
    "make_gif(files, \"results/harmonic/nophysics.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic/nophysics.gif\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training WITH Physics-Informed Loss Term\n",
    "\n",
    "Apparently, the baseline model without a physics loss term didn't generalize well to unseen time steps. Now, let's add a physics loss term to make it predict beyond training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(model)\n",
    "        \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "files = []\n",
    "\n",
    "save_dir = 'results/harmonic'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "MAX_ITER = 30000\n",
    "N_COLLOCATION_POINTS = 30\n",
    "input = training_data[:,:1].clone().detach()    # t\n",
    "output = training_data[:,1:].clone().detach()  # x\n",
    "collocation_t = torch.linspace(0,Tmax,N_COLLOCATION_POINTS)\n",
    "collocation_pts = torch.unsqueeze(collocation_t, -1).clone().detach().requires_grad_(True)\n",
    "for iter in range(MAX_ITER):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(input)\n",
    "    data_loss = torch.mean((output-prediction)**2)\n",
    "    \n",
    "    prediction_colloc = model(collocation_pts)\n",
    "    dx  = torch.autograd.grad(prediction_colloc, collocation_pts, torch.ones_like(prediction_colloc), create_graph=True)[0]\n",
    "    ddx  = torch.autograd.grad(dx, collocation_pts, torch.ones_like(dx), create_graph=True)[0]\n",
    "    residual = ddx + 2*zeta*omega0*dx + (omega0**2)*prediction_colloc\n",
    "    physics_loss = torch.mean(residual**2)\n",
    "\n",
    "    loss = data_loss + (1e-4)*physics_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().numpy():.5e}, physics: {physics_loss.detach().numpy():.5e}\", end='\\r')\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (iter+1) % 100 == 0: \n",
    "        \n",
    "        prediction = model(torch.unsqueeze(t,axis=-1)).detach()\n",
    "\n",
    "        plot_progress(t, GT, prediction, training_data, collocation_t)\n",
    "        files.append(save_progress(save_dir, 'pinn', iter))\n",
    "    \n",
    "        if (iter+1) % 1000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(files, \"results/harmonic/pinn.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic/pinn.gif\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
